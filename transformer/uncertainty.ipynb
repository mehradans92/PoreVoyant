{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      "3.10.12\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sartaaj/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MOFormer_modded.transformer import Transformer, TransformerRegressor\n",
    "from MOFormer_modded.dataset_modded import MOF_ID_Dataset\n",
    "from MOFormer_modded.tokenizer.mof_tokenizer import MOFTokenizer\n",
    "import yaml\n",
    "from MOFormer_modded.model.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_456105/1200223640.py:1: DtypeWarning: Columns (40,41,43,44,45,46,47,49,50,51,52,53,55,56,57,65,66,67,68,69,77,78,79,80,81,89,90,91,92,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  qmof_df = pd.read_csv(\"qmof.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qmof_id</th>\n",
       "      <th>name</th>\n",
       "      <th>info.formula</th>\n",
       "      <th>info.formula_reduced</th>\n",
       "      <th>info.mofid.mofid</th>\n",
       "      <th>info.mofid.mofkey</th>\n",
       "      <th>info.mofid.smiles_nodes</th>\n",
       "      <th>info.mofid.smiles_linkers</th>\n",
       "      <th>info.mofid.smiles</th>\n",
       "      <th>info.mofid.topology</th>\n",
       "      <th>...</th>\n",
       "      <th>outputs.hse06.energy_elec</th>\n",
       "      <th>outputs.hse06.net_magmom</th>\n",
       "      <th>outputs.hse06.bandgap</th>\n",
       "      <th>outputs.hse06.cbm</th>\n",
       "      <th>outputs.hse06.vbm</th>\n",
       "      <th>outputs.hse06.directgap</th>\n",
       "      <th>outputs.hse06.bandgap_spins</th>\n",
       "      <th>outputs.hse06.cbm_spins</th>\n",
       "      <th>outputs.hse06.vbm_spins</th>\n",
       "      <th>outputs.hse06.directgap_spins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qmof-8a95c27</td>\n",
       "      <td>ABACUF01_FSR</td>\n",
       "      <td>Ba2CuC6H14O16</td>\n",
       "      <td>Ba2CuC6H14O16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['O', '[Ba]', '[Cu]']</td>\n",
       "      <td>['[O-]C=O']</td>\n",
       "      <td>O.[Ba].[Cu].[O-]C=O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qmof-019ba28</td>\n",
       "      <td>ABALOF_FSR</td>\n",
       "      <td>Cu12C36H56I16N4S4</td>\n",
       "      <td>Cu3C9H14I4NS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qmof-830ed1c</td>\n",
       "      <td>ABAVIJ_FSR</td>\n",
       "      <td>Co4C48H32N8O16</td>\n",
       "      <td>CoC12H8N2O4</td>\n",
       "      <td>[Co].[O-]C(=O)c1ccncc1 MOFid-v1.rtl.cat0</td>\n",
       "      <td>Co.TWBYWOBDOCUKOW.MOFkey-v1.rtl</td>\n",
       "      <td>['[Co]']</td>\n",
       "      <td>['[O-]C(=O)c1ccncc1']</td>\n",
       "      <td>[Co].[O-]C(=O)c1ccncc1</td>\n",
       "      <td>rtl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qmof-5bd4a24</td>\n",
       "      <td>ABAVOP_FSR</td>\n",
       "      <td>Co4C48H32N8O16</td>\n",
       "      <td>CoC12H8N2O4</td>\n",
       "      <td>[Co].[O-]C(=O)c1ccncc1 MOFid-v1.rtl.cat0</td>\n",
       "      <td>Co.TWBYWOBDOCUKOW.MOFkey-v1.rtl</td>\n",
       "      <td>['[Co]']</td>\n",
       "      <td>['[O-]C(=O)c1ccncc1']</td>\n",
       "      <td>[Co].[O-]C(=O)c1ccncc1</td>\n",
       "      <td>rtl</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qmof-644aab4</td>\n",
       "      <td>ABAXUZ_FSR</td>\n",
       "      <td>Zn2C50H32N6O8S4</td>\n",
       "      <td>ZnC25H16N3O4S2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['[Zn][Zn]']</td>\n",
       "      <td>['[O-]C(=O)c1cccc(c1)c1nccs1', 'n1ccc(cc1)c1cc...</td>\n",
       "      <td>[O-]C(=O)c1cccc(c1)c1nccs1.[Zn][Zn].n1ccc(cc1)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-811.553858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.901747</td>\n",
       "      <td>2.246703</td>\n",
       "      <td>-0.655044</td>\n",
       "      <td>True</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20370</th>\n",
       "      <td>qmof-7aebbbb</td>\n",
       "      <td>tobacco_srsb_sym_3_on_2_sym_3_mc_0_L_2</td>\n",
       "      <td>Cu12C84H60N24</td>\n",
       "      <td>CuC7H5N2</td>\n",
       "      <td>N1=C[C](C=N1)C=Cc1cc(C=CC2=C[N]N=C2)cc(c1)C=CC...</td>\n",
       "      <td>Cu.IBPUNEAULYEGJU.MOFkey-v1.srs</td>\n",
       "      <td>['[Cu]']</td>\n",
       "      <td>['N1=C[C](C=N1)C=Cc1cc(C=CC2=C[N]N=C2)cc(c1)C=...</td>\n",
       "      <td>N1=C[C](C=N1)C=Cc1cc(C=CC2=C[N]N=C2)cc(c1)C=CC...</td>\n",
       "      <td>srs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20371</th>\n",
       "      <td>qmof-9a04c15</td>\n",
       "      <td>tobacco_srsb_sym_3_on_2_sym_3_mc_0_L_6</td>\n",
       "      <td>Cu12C84H48N60</td>\n",
       "      <td>CuC7H4N5</td>\n",
       "      <td>N1=C[C](C=N1)n1nnc(c1)c1cc(cc(c1)c1nnn(c1)C1=C...</td>\n",
       "      <td>Cu.JWLDCPHWRGZUAB.MOFkey-v1.srs</td>\n",
       "      <td>['[Cu]']</td>\n",
       "      <td>['N1=C[C](C=N1)n1nnc(c1)c1cc(cc(c1)c1nnn(c1)C1...</td>\n",
       "      <td>N1=C[C](C=N1)n1nnc(c1)c1cc(cc(c1)c1nnn(c1)C1=C...</td>\n",
       "      <td>srs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20372</th>\n",
       "      <td>qmof-0dce90f</td>\n",
       "      <td>tobacco_srsb_sym_3_on_2_sym_3_mc_0__</td>\n",
       "      <td>Cu12C60H36N24</td>\n",
       "      <td>CuC5H3N2</td>\n",
       "      <td>N1=C[C](C=N1)c1cc(cc(c1)C1=CN=N[CH]1)C1=C[N]N=...</td>\n",
       "      <td>Cu.PJSMFZDMZONQKK.MOFkey-v1.srs</td>\n",
       "      <td>['[Cu]', '[Cu][Cu]']</td>\n",
       "      <td>['N1=C[C](C=N1)c1cc(cc(c1)C1=CN=N[CH]1)C1=C[N]...</td>\n",
       "      <td>N1=C[C](C=N1)c1cc(cc(c1)C1=CN=N[CH]1)C1=C[N]N=...</td>\n",
       "      <td>srs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20373</th>\n",
       "      <td>qmof-955fe88</td>\n",
       "      <td>tobacco_srsb_sym_3_on_4_sym_3_mc_0_L_2</td>\n",
       "      <td>Cu12C112H72N24</td>\n",
       "      <td>Cu3C28H18N6</td>\n",
       "      <td>N1=C[C](C=N1)C=CC1=CC2=CC(=CC3=CC(=CC(=C1)[C]2...</td>\n",
       "      <td>Cu.WCJPEIPZJUESBA.MOFkey-v1.srs</td>\n",
       "      <td>['[Cu]']</td>\n",
       "      <td>['N1=C[C](C=N1)C=CC1=CC2=CC(=CC3=CC(=CC(=C1)[C...</td>\n",
       "      <td>N1=C[C](C=N1)C=CC1=CC2=CC(=CC3=CC(=CC(=C1)[C]2...</td>\n",
       "      <td>srs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20374</th>\n",
       "      <td>qmof-6538047</td>\n",
       "      <td>tobacco_srsb_sym_3_on_5_sym_3_mc_0_L_2</td>\n",
       "      <td>Cu12C108H72N36</td>\n",
       "      <td>CuC9H6N3</td>\n",
       "      <td>N1=C[C](C=N1)C=Cn1cc2c(c1)c1cn(cc1c1c2cn(c1)C=...</td>\n",
       "      <td>Cu.HPUZBJXKDGSLPP.MOFkey-v1.srs</td>\n",
       "      <td>['[Cu]', '[Cu][Cu]']</td>\n",
       "      <td>['N1=C[C](C=N1)C=Cn1cc2c(c1)c1cn(cc1c1c2cn(c1)...</td>\n",
       "      <td>N1=C[C](C=N1)C=Cn1cc2c(c1)c1cn(cc1c1c2cn(c1)C=...</td>\n",
       "      <td>srs</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20375 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qmof_id                                    name  \\\n",
       "0      qmof-8a95c27                            ABACUF01_FSR   \n",
       "1      qmof-019ba28                              ABALOF_FSR   \n",
       "2      qmof-830ed1c                              ABAVIJ_FSR   \n",
       "3      qmof-5bd4a24                              ABAVOP_FSR   \n",
       "4      qmof-644aab4                              ABAXUZ_FSR   \n",
       "...             ...                                     ...   \n",
       "20370  qmof-7aebbbb  tobacco_srsb_sym_3_on_2_sym_3_mc_0_L_2   \n",
       "20371  qmof-9a04c15  tobacco_srsb_sym_3_on_2_sym_3_mc_0_L_6   \n",
       "20372  qmof-0dce90f    tobacco_srsb_sym_3_on_2_sym_3_mc_0__   \n",
       "20373  qmof-955fe88  tobacco_srsb_sym_3_on_4_sym_3_mc_0_L_2   \n",
       "20374  qmof-6538047  tobacco_srsb_sym_3_on_5_sym_3_mc_0_L_2   \n",
       "\n",
       "            info.formula info.formula_reduced  \\\n",
       "0          Ba2CuC6H14O16        Ba2CuC6H14O16   \n",
       "1      Cu12C36H56I16N4S4         Cu3C9H14I4NS   \n",
       "2         Co4C48H32N8O16          CoC12H8N2O4   \n",
       "3         Co4C48H32N8O16          CoC12H8N2O4   \n",
       "4        Zn2C50H32N6O8S4       ZnC25H16N3O4S2   \n",
       "...                  ...                  ...   \n",
       "20370      Cu12C84H60N24             CuC7H5N2   \n",
       "20371      Cu12C84H48N60             CuC7H4N5   \n",
       "20372      Cu12C60H36N24             CuC5H3N2   \n",
       "20373     Cu12C112H72N24          Cu3C28H18N6   \n",
       "20374     Cu12C108H72N36             CuC9H6N3   \n",
       "\n",
       "                                        info.mofid.mofid  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2               [Co].[O-]C(=O)c1ccncc1 MOFid-v1.rtl.cat0   \n",
       "3               [Co].[O-]C(=O)c1ccncc1 MOFid-v1.rtl.cat0   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "20370  N1=C[C](C=N1)C=Cc1cc(C=CC2=C[N]N=C2)cc(c1)C=CC...   \n",
       "20371  N1=C[C](C=N1)n1nnc(c1)c1cc(cc(c1)c1nnn(c1)C1=C...   \n",
       "20372  N1=C[C](C=N1)c1cc(cc(c1)C1=CN=N[CH]1)C1=C[N]N=...   \n",
       "20373  N1=C[C](C=N1)C=CC1=CC2=CC(=CC3=CC(=CC(=C1)[C]2...   \n",
       "20374  N1=C[C](C=N1)C=Cn1cc2c(c1)c1cn(cc1c1c2cn(c1)C=...   \n",
       "\n",
       "                     info.mofid.mofkey info.mofid.smiles_nodes  \\\n",
       "0                                  NaN   ['O', '[Ba]', '[Cu]']   \n",
       "1                                  NaN                     NaN   \n",
       "2      Co.TWBYWOBDOCUKOW.MOFkey-v1.rtl                ['[Co]']   \n",
       "3      Co.TWBYWOBDOCUKOW.MOFkey-v1.rtl                ['[Co]']   \n",
       "4                                  NaN            ['[Zn][Zn]']   \n",
       "...                                ...                     ...   \n",
       "20370  Cu.IBPUNEAULYEGJU.MOFkey-v1.srs                ['[Cu]']   \n",
       "20371  Cu.JWLDCPHWRGZUAB.MOFkey-v1.srs                ['[Cu]']   \n",
       "20372  Cu.PJSMFZDMZONQKK.MOFkey-v1.srs    ['[Cu]', '[Cu][Cu]']   \n",
       "20373  Cu.WCJPEIPZJUESBA.MOFkey-v1.srs                ['[Cu]']   \n",
       "20374  Cu.HPUZBJXKDGSLPP.MOFkey-v1.srs    ['[Cu]', '[Cu][Cu]']   \n",
       "\n",
       "                               info.mofid.smiles_linkers  \\\n",
       "0                                            ['[O-]C=O']   \n",
       "1                                                    NaN   \n",
       "2                                  ['[O-]C(=O)c1ccncc1']   \n",
       "3                                  ['[O-]C(=O)c1ccncc1']   \n",
       "4      ['[O-]C(=O)c1cccc(c1)c1nccs1', 'n1ccc(cc1)c1cc...   \n",
       "...                                                  ...   \n",
       "20370  ['N1=C[C](C=N1)C=Cc1cc(C=CC2=C[N]N=C2)cc(c1)C=...   \n",
       "20371  ['N1=C[C](C=N1)n1nnc(c1)c1cc(cc(c1)c1nnn(c1)C1...   \n",
       "20372  ['N1=C[C](C=N1)c1cc(cc(c1)C1=CN=N[CH]1)C1=C[N]...   \n",
       "20373  ['N1=C[C](C=N1)C=CC1=CC2=CC(=CC3=CC(=CC(=C1)[C...   \n",
       "20374  ['N1=C[C](C=N1)C=Cn1cc2c(c1)c1cn(cc1c1c2cn(c1)...   \n",
       "\n",
       "                                       info.mofid.smiles info.mofid.topology  \\\n",
       "0                                    O.[Ba].[Cu].[O-]C=O                 NaN   \n",
       "1                                                    NaN                 NaN   \n",
       "2                                 [Co].[O-]C(=O)c1ccncc1                 rtl   \n",
       "3                                 [Co].[O-]C(=O)c1ccncc1                 rtl   \n",
       "4      [O-]C(=O)c1cccc(c1)c1nccs1.[Zn][Zn].n1ccc(cc1)...                 NaN   \n",
       "...                                                  ...                 ...   \n",
       "20370  N1=C[C](C=N1)C=Cc1cc(C=CC2=C[N]N=C2)cc(c1)C=CC...                 srs   \n",
       "20371  N1=C[C](C=N1)n1nnc(c1)c1cc(cc(c1)c1nnn(c1)C1=C...                 srs   \n",
       "20372  N1=C[C](C=N1)c1cc(cc(c1)C1=CN=N[CH]1)C1=C[N]N=...                 srs   \n",
       "20373  N1=C[C](C=N1)C=CC1=CC2=CC(=CC3=CC(=CC(=C1)[C]2...                 srs   \n",
       "20374  N1=C[C](C=N1)C=Cn1cc2c(c1)c1cn(cc1c1c2cn(c1)C=...                 srs   \n",
       "\n",
       "       ...  outputs.hse06.energy_elec  outputs.hse06.net_magmom  \\\n",
       "0      ...                        NaN                       NaN   \n",
       "1      ...                        NaN                       NaN   \n",
       "2      ...                        NaN                       NaN   \n",
       "3      ...                        NaN                       NaN   \n",
       "4      ...                -811.553858                       0.0   \n",
       "...    ...                        ...                       ...   \n",
       "20370  ...                        NaN                       NaN   \n",
       "20371  ...                        NaN                       NaN   \n",
       "20372  ...                        NaN                       NaN   \n",
       "20373  ...                        NaN                       NaN   \n",
       "20374  ...                        NaN                       NaN   \n",
       "\n",
       "       outputs.hse06.bandgap  outputs.hse06.cbm  outputs.hse06.vbm  \\\n",
       "0                        NaN                NaN                NaN   \n",
       "1                        NaN                NaN                NaN   \n",
       "2                        NaN                NaN                NaN   \n",
       "3                        NaN                NaN                NaN   \n",
       "4                   2.901747           2.246703          -0.655044   \n",
       "...                      ...                ...                ...   \n",
       "20370                    NaN                NaN                NaN   \n",
       "20371                    NaN                NaN                NaN   \n",
       "20372                    NaN                NaN                NaN   \n",
       "20373                    NaN                NaN                NaN   \n",
       "20374                    NaN                NaN                NaN   \n",
       "\n",
       "      outputs.hse06.directgap  outputs.hse06.bandgap_spins  \\\n",
       "0                         NaN                          NaN   \n",
       "1                         NaN                          NaN   \n",
       "2                         NaN                          NaN   \n",
       "3                         NaN                          NaN   \n",
       "4                        True                 [None, None]   \n",
       "...                       ...                          ...   \n",
       "20370                     NaN                          NaN   \n",
       "20371                     NaN                          NaN   \n",
       "20372                     NaN                          NaN   \n",
       "20373                     NaN                          NaN   \n",
       "20374                     NaN                          NaN   \n",
       "\n",
       "      outputs.hse06.cbm_spins outputs.hse06.vbm_spins  \\\n",
       "0                         NaN                     NaN   \n",
       "1                         NaN                     NaN   \n",
       "2                         NaN                     NaN   \n",
       "3                         NaN                     NaN   \n",
       "4                [None, None]            [None, None]   \n",
       "...                       ...                     ...   \n",
       "20370                     NaN                     NaN   \n",
       "20371                     NaN                     NaN   \n",
       "20372                     NaN                     NaN   \n",
       "20373                     NaN                     NaN   \n",
       "20374                     NaN                     NaN   \n",
       "\n",
       "       outputs.hse06.directgap_spins  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2                                NaN  \n",
       "3                                NaN  \n",
       "4                       [None, None]  \n",
       "...                              ...  \n",
       "20370                            NaN  \n",
       "20371                            NaN  \n",
       "20372                            NaN  \n",
       "20373                            NaN  \n",
       "20374                            NaN  \n",
       "\n",
       "[20375 rows x 94 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmof_df = pd.read_csv(\"qmof.csv\")\n",
    "qmof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.632527\n",
       "1        1.134232\n",
       "2        0.345448\n",
       "3        0.342645\n",
       "4        1.973007\n",
       "           ...   \n",
       "20370    2.692705\n",
       "20371    3.326284\n",
       "20372    3.383629\n",
       "20373    0.660589\n",
       "20374    2.348021\n",
       "Name: outputs.pbe.bandgap, Length: 20375, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmof_df['outputs.pbe.bandgap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOFid</th>\n",
       "      <th>Band Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O-]C(=O)c1cc2c3c(c1)c(N(=O)=O)c(c1c3c(c(c2N(=...</td>\n",
       "      <td>2.201034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cl[Cd].O=C1[N]NC(=O)c2c1nccc2&amp;&amp;fes.cat0</td>\n",
       "      <td>2.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Zn].c1ccc2c(c1)N=C[N]2&amp;&amp;sod.cat0</td>\n",
       "      <td>3.677709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Cu].[O-]C(=O)CCc1cccnc1&amp;&amp;sql.cat0</td>\n",
       "      <td>0.959976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fc1cncc(c1C#Cc1c(F)cncc1F)F.[O-]C(=O)c1c(Cl)c(...</td>\n",
       "      <td>1.098963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7461</th>\n",
       "      <td>[O-]C(=O)c1cc(cc(c1)N(=O)=O)C(=O)[O-].[Zn].c1n...</td>\n",
       "      <td>2.038372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>O=C(c1ccncc1)N1CCN(CC1)C(=O)c1ccncc1.[O-]C(=O)...</td>\n",
       "      <td>1.747641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7463</th>\n",
       "      <td>COc1cc2ccc3c(c2cc1C(=O)[O-])ccc1c3cc(C(=O)[O-]...</td>\n",
       "      <td>1.665536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>[Ni].c1ccc(cn1)[CH][N][N][CH]c1cccnc1&amp;&amp;cdt.cat0</td>\n",
       "      <td>1.388292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>[Cd].[O-]C(=O)c1cccc(c1)C(=O)[O-]&amp;&amp;sql.cat1</td>\n",
       "      <td>3.172720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  MOFid  Band Gap\n",
       "0     [O-]C(=O)c1cc2c3c(c1)c(N(=O)=O)c(c1c3c(c(c2N(=...  2.201034\n",
       "1               Cl[Cd].O=C1[N]NC(=O)c2c1nccc2&&fes.cat0  2.055500\n",
       "2                     [Zn].c1ccc2c(c1)N=C[N]2&&sod.cat0  3.677709\n",
       "3                    [Cu].[O-]C(=O)CCc1cccnc1&&sql.cat0  0.959976\n",
       "4     Fc1cncc(c1C#Cc1c(F)cncc1F)F.[O-]C(=O)c1c(Cl)c(...  1.098963\n",
       "...                                                 ...       ...\n",
       "7461  [O-]C(=O)c1cc(cc(c1)N(=O)=O)C(=O)[O-].[Zn].c1n...  2.038372\n",
       "7462  O=C(c1ccncc1)N1CCN(CC1)C(=O)c1ccncc1.[O-]C(=O)...  1.747641\n",
       "7463  COc1cc2ccc3c(c2cc1C(=O)[O-])ccc1c3cc(C(=O)[O-]...  1.665536\n",
       "7464    [Ni].c1ccc(cn1)[CH][N][N][CH]c1cccnc1&&cdt.cat0  1.388292\n",
       "7465        [Cd].[O-]C(=O)c1cccc(c1)C(=O)[O-]&&sql.cat1  3.172720\n",
       "\n",
       "[7466 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmof_mofid = pd.read_csv(\"QMOF_small_mofid.csv\", header = None)\n",
    "qmof_mofid.columns = ['MOFid', 'Band Gap']\n",
    "qmof_mofid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_smiles_stable = {'qmof_ID' : [],\n",
    "                    'SMILES' : [],\n",
    "                    'Band Gap' : []\n",
    "                    }\n",
    "\n",
    "for i in qmof_mofid['MOFid'].values:\n",
    "    smiles = i.split('&&')[0]\n",
    "    try:\n",
    "        qmof_id = qmof_df[qmof_df['info.mofid.smiles'] == smiles]['qmof_id'].values[0]\n",
    "        bandgap = qmof_mofid[qmof_mofid['MOFid'] == i]['Band Gap'].values[0]\n",
    "\n",
    "        id_smiles_stable['SMILES'].append(smiles)\n",
    "        id_smiles_stable['qmof_ID'].append(qmof_id)\n",
    "        id_smiles_stable['Band Gap'].append(bandgap)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qmof_ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Band Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qmof-02f9568</td>\n",
       "      <td>[O-]C(=O)c1cc2c3c(c1)c(N(=O)=O)c(c1c3c(c(c2N(=...</td>\n",
       "      <td>2.201034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qmof-f8ab6e6</td>\n",
       "      <td>Cl[Cd].O=C1[N]NC(=O)c2c1nccc2</td>\n",
       "      <td>2.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qmof-ac208a4</td>\n",
       "      <td>[Zn].c1ccc2c(c1)N=C[N]2</td>\n",
       "      <td>3.677709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qmof-d967b7b</td>\n",
       "      <td>[Cu].[O-]C(=O)CCc1cccnc1</td>\n",
       "      <td>0.959976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qmof-c7f2375</td>\n",
       "      <td>Fc1cncc(c1C#Cc1c(F)cncc1F)F.[O-]C(=O)c1c(Cl)c(...</td>\n",
       "      <td>1.098963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>qmof-87a0280</td>\n",
       "      <td>[O-]C(=O)c1cc(cc(c1)N(=O)=O)C(=O)[O-].[Zn].c1n...</td>\n",
       "      <td>2.038372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>qmof-c645675</td>\n",
       "      <td>O=C(c1ccncc1)N1CCN(CC1)C(=O)c1ccncc1.[O-]C(=O)...</td>\n",
       "      <td>1.747641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>qmof-b2c7c73</td>\n",
       "      <td>COc1cc2ccc3c(c2cc1C(=O)[O-])ccc1c3cc(C(=O)[O-]...</td>\n",
       "      <td>1.665536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>qmof-fcb8885</td>\n",
       "      <td>[Ni].c1ccc(cn1)[CH][N][N][CH]c1cccnc1</td>\n",
       "      <td>1.388292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>qmof-d8acb74</td>\n",
       "      <td>[Cd].[O-]C(=O)c1cccc(c1)C(=O)[O-]</td>\n",
       "      <td>3.172720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7190 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           qmof_ID                                             SMILES  \\\n",
       "0     qmof-02f9568  [O-]C(=O)c1cc2c3c(c1)c(N(=O)=O)c(c1c3c(c(c2N(=...   \n",
       "1     qmof-f8ab6e6                      Cl[Cd].O=C1[N]NC(=O)c2c1nccc2   \n",
       "2     qmof-ac208a4                            [Zn].c1ccc2c(c1)N=C[N]2   \n",
       "3     qmof-d967b7b                           [Cu].[O-]C(=O)CCc1cccnc1   \n",
       "4     qmof-c7f2375  Fc1cncc(c1C#Cc1c(F)cncc1F)F.[O-]C(=O)c1c(Cl)c(...   \n",
       "...            ...                                                ...   \n",
       "7185  qmof-87a0280  [O-]C(=O)c1cc(cc(c1)N(=O)=O)C(=O)[O-].[Zn].c1n...   \n",
       "7186  qmof-c645675  O=C(c1ccncc1)N1CCN(CC1)C(=O)c1ccncc1.[O-]C(=O)...   \n",
       "7187  qmof-b2c7c73  COc1cc2ccc3c(c2cc1C(=O)[O-])ccc1c3cc(C(=O)[O-]...   \n",
       "7188  qmof-fcb8885              [Ni].c1ccc(cn1)[CH][N][N][CH]c1cccnc1   \n",
       "7189  qmof-d8acb74                  [Cd].[O-]C(=O)c1cccc(c1)C(=O)[O-]   \n",
       "\n",
       "      Band Gap  \n",
       "0     2.201034  \n",
       "1     2.055500  \n",
       "2     3.677709  \n",
       "3     0.959976  \n",
       "4     1.098963  \n",
       "...        ...  \n",
       "7185  2.038372  \n",
       "7186  1.747641  \n",
       "7187  1.665536  \n",
       "7188  1.388292  \n",
       "7189  3.172720  \n",
       "\n",
       "[7190 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(id_smiles_stable)\n",
    "data_df = data_df.dropna()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MOFTokenizer(\"MOFormer_modded/tokenizer/vocab_full.txt\")\n",
    "config = yaml.load(open(\"MOFormer_modded/config_ft_transformer.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "config['dataloader']['randomSeed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'epochs': 200, 'eval_every_n_epochs': 1, 'fine_tune_from': './training_results/pretraining', 'trained_with': 'CGCNN', 'log_every_n_steps': 1, 'gpu': 'cuda:0', 'vocab_path': 'MOFormer_modded/tokenizer/vocab_full.txt', 'cuda': True, 'num_workers': 0, 'task': 'classification', 'optim': {'optimizer': 'Adam', 'init_lr': 5e-05, 'weight_decay': '1e-6'}, 'dataloader': {'valid_ratio': 0.15, 'test_ratio': 0.15, 'use_ratio': 1, 'randomSeed': 0}, 'dataset': {'data_name': 'QMOF', 'dataPath': './MOFormer_modded/dataset/core_ch4uptake_highP.csv'}, 'Transformer': {'ntoken': 4021, 'd_model': 512, 'nhead': 8, 'd_hid': 512, 'nlayers': 6, 'dropout': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.to_numpy()\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state=42)\n",
    "\n",
    "folds = []\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train_fold, test_fold = data[train_index], data[test_index]\n",
    "    folds.append((train_fold, test_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1438, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MOFormer_modded.transformer import PositionalEncoding\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.token_encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        # initrange = 0.1\n",
    "        # self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        nn.init.xavier_normal_(self.token_encoder.weight)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.token_encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output[:, 0:1, :] #this was added in by me\n",
    "\n",
    "        return output.squeeze(dim = 1) #this was added in by me\n",
    "        #return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTransformer(nn.Module):\n",
    "    def __init__(self, transformer, input_dim = 512, hidden_dim = 256, output_dim = 1):\n",
    "        super(ClassificationTransformer, self).__init__()\n",
    "        self.transformer = transformer\n",
    "\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        ) #nn.Sigmoid was here before\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim = 1)\n",
    "        x = self.classification_head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class RegressionTransformer(nn.Module):\n",
    "    def __init__(self, model, mlp_hidden_dim=256):\n",
    "        super(RegressionTransformer, self).__init__()\n",
    "        \n",
    "        #initialize model itself\n",
    "        self.model = model\n",
    "\n",
    "        #regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(512, mlp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        #only updating MLP regression head\n",
    "        #for params in self.model.parameters():\n",
    "        #    params.requires_grad = False\n",
    "                \n",
    "    def forward(self, smiles):\n",
    "        transformer_output = self.model(smiles)\n",
    "\n",
    "        output = self.regression_head(transformer_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: pos_encoder.pe\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.0.linear1.weight\n",
      "loaded: transformer_encoder.layers.0.linear1.bias\n",
      "loaded: transformer_encoder.layers.0.linear2.weight\n",
      "loaded: transformer_encoder.layers.0.linear2.bias\n",
      "loaded: transformer_encoder.layers.0.norm1.weight\n",
      "loaded: transformer_encoder.layers.0.norm1.bias\n",
      "loaded: transformer_encoder.layers.0.norm2.weight\n",
      "loaded: transformer_encoder.layers.0.norm2.bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.1.linear1.weight\n",
      "loaded: transformer_encoder.layers.1.linear1.bias\n",
      "loaded: transformer_encoder.layers.1.linear2.weight\n",
      "loaded: transformer_encoder.layers.1.linear2.bias\n",
      "loaded: transformer_encoder.layers.1.norm1.weight\n",
      "loaded: transformer_encoder.layers.1.norm1.bias\n",
      "loaded: transformer_encoder.layers.1.norm2.weight\n",
      "loaded: transformer_encoder.layers.1.norm2.bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.2.linear1.weight\n",
      "loaded: transformer_encoder.layers.2.linear1.bias\n",
      "loaded: transformer_encoder.layers.2.linear2.weight\n",
      "loaded: transformer_encoder.layers.2.linear2.bias\n",
      "loaded: transformer_encoder.layers.2.norm1.weight\n",
      "loaded: transformer_encoder.layers.2.norm1.bias\n",
      "loaded: transformer_encoder.layers.2.norm2.weight\n",
      "loaded: transformer_encoder.layers.2.norm2.bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.3.linear1.weight\n",
      "loaded: transformer_encoder.layers.3.linear1.bias\n",
      "loaded: transformer_encoder.layers.3.linear2.weight\n",
      "loaded: transformer_encoder.layers.3.linear2.bias\n",
      "loaded: transformer_encoder.layers.3.norm1.weight\n",
      "loaded: transformer_encoder.layers.3.norm1.bias\n",
      "loaded: transformer_encoder.layers.3.norm2.weight\n",
      "loaded: transformer_encoder.layers.3.norm2.bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.4.linear1.weight\n",
      "loaded: transformer_encoder.layers.4.linear1.bias\n",
      "loaded: transformer_encoder.layers.4.linear2.weight\n",
      "loaded: transformer_encoder.layers.4.linear2.bias\n",
      "loaded: transformer_encoder.layers.4.norm1.weight\n",
      "loaded: transformer_encoder.layers.4.norm1.bias\n",
      "loaded: transformer_encoder.layers.4.norm2.weight\n",
      "loaded: transformer_encoder.layers.4.norm2.bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.5.linear1.weight\n",
      "loaded: transformer_encoder.layers.5.linear1.bias\n",
      "loaded: transformer_encoder.layers.5.linear2.weight\n",
      "loaded: transformer_encoder.layers.5.linear2.bias\n",
      "loaded: transformer_encoder.layers.5.norm1.weight\n",
      "loaded: transformer_encoder.layers.5.norm1.bias\n",
      "loaded: transformer_encoder.layers.5.norm2.weight\n",
      "loaded: transformer_encoder.layers.5.norm2.bias\n",
      "loaded: token_encoder.weight\n",
      "Loaded pre-trained model with success.\n"
     ]
    }
   ],
   "source": [
    "def _load_pre_trained_weights(model, mode = 'cgcnn'):\n",
    "    \"\"\"\n",
    "    Taken from this repository: https://github.com/zcao0420/MOFormer/blob/main/finetune_transformer.py\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # checkpoints_folder = os.path.join(self.config['fine_tune_from'], 'checkpoints')\n",
    "        #checkpoints_folder = 'SSL/pretrained/transformer'\n",
    "        checkpoints_folder = 'SSL/pretrained/cgcnn'\n",
    "        if mode == 'geometric':\n",
    "            checkpoints_folder = 'SSL/pretrained/geometric'\n",
    "\n",
    "        elif mode == 'cgcnn':\n",
    "            checkpoints_folder = 'SSL/pretrained/transformer'\n",
    "        \n",
    "        else:\n",
    "            checkpoints_folder = 'SSL/pretrained/None'\n",
    "\n",
    "        load_state = torch.load(os.path.join(checkpoints_folder, 'model_t_50.pth'),  map_location=config['gpu']) \n",
    "        model_state = model.state_dict()\n",
    "\n",
    "        for name, param in load_state.items():\n",
    "            if name not in model_state:\n",
    "                print('NOT loaded:', name)\n",
    "                continue\n",
    "            else:\n",
    "                print('loaded:', name)\n",
    "            if isinstance(param, nn.parameter.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            model_state[name].copy_(param)\n",
    "        print(\"Loaded pre-trained model with success.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Pre-trained weights not found. Training from scratch.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "transformer_SMILES = Transformer(**config['Transformer'])\n",
    "model_pre = _load_pre_trained_weights(model = transformer_SMILES, mode = 'cgcnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and config['gpu'] != 'cpu':\n",
    "    device = config['gpu']\n",
    "    torch.cuda.set_device(device)\n",
    "    config['cuda'] = True\n",
    "\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    config['cuda'] = False\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ClassificationTransformer(transformer = model_pre)\n",
    "model = RegressionTransformer(model = model_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.Adam(model.regression_head.parameters(), lr = 0.01)\n",
    "optimizer_t = optim.Adam(model.model.parameters(), lr = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for evaluation\n",
    "batch_size = 64\n",
    "\n",
    "fifth_db = MOF_ID_Dataset(data = folds[4], tokenizer = tokenizer)\n",
    "\n",
    "fifth_fold = DataLoader(\n",
    "                        fifth_db, batch_size=batch_size, drop_last=True, shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model number: 0\n",
      "loaded: pos_encoder.pe\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.0.linear1.weight\n",
      "loaded: transformer_encoder.layers.0.linear1.bias\n",
      "loaded: transformer_encoder.layers.0.linear2.weight\n",
      "loaded: transformer_encoder.layers.0.linear2.bias\n",
      "loaded: transformer_encoder.layers.0.norm1.weight\n",
      "loaded: transformer_encoder.layers.0.norm1.bias\n",
      "loaded: transformer_encoder.layers.0.norm2.weight\n",
      "loaded: transformer_encoder.layers.0.norm2.bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.1.linear1.weight\n",
      "loaded: transformer_encoder.layers.1.linear1.bias\n",
      "loaded: transformer_encoder.layers.1.linear2.weight\n",
      "loaded: transformer_encoder.layers.1.linear2.bias\n",
      "loaded: transformer_encoder.layers.1.norm1.weight\n",
      "loaded: transformer_encoder.layers.1.norm1.bias\n",
      "loaded: transformer_encoder.layers.1.norm2.weight\n",
      "loaded: transformer_encoder.layers.1.norm2.bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.2.linear1.weight\n",
      "loaded: transformer_encoder.layers.2.linear1.bias\n",
      "loaded: transformer_encoder.layers.2.linear2.weight\n",
      "loaded: transformer_encoder.layers.2.linear2.bias\n",
      "loaded: transformer_encoder.layers.2.norm1.weight\n",
      "loaded: transformer_encoder.layers.2.norm1.bias\n",
      "loaded: transformer_encoder.layers.2.norm2.weight\n",
      "loaded: transformer_encoder.layers.2.norm2.bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.3.linear1.weight\n",
      "loaded: transformer_encoder.layers.3.linear1.bias\n",
      "loaded: transformer_encoder.layers.3.linear2.weight\n",
      "loaded: transformer_encoder.layers.3.linear2.bias\n",
      "loaded: transformer_encoder.layers.3.norm1.weight\n",
      "loaded: transformer_encoder.layers.3.norm1.bias\n",
      "loaded: transformer_encoder.layers.3.norm2.weight\n",
      "loaded: transformer_encoder.layers.3.norm2.bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.4.linear1.weight\n",
      "loaded: transformer_encoder.layers.4.linear1.bias\n",
      "loaded: transformer_encoder.layers.4.linear2.weight\n",
      "loaded: transformer_encoder.layers.4.linear2.bias\n",
      "loaded: transformer_encoder.layers.4.norm1.weight\n",
      "loaded: transformer_encoder.layers.4.norm1.bias\n",
      "loaded: transformer_encoder.layers.4.norm2.weight\n",
      "loaded: transformer_encoder.layers.4.norm2.bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.5.linear1.weight\n",
      "loaded: transformer_encoder.layers.5.linear1.bias\n",
      "loaded: transformer_encoder.layers.5.linear2.weight\n",
      "loaded: transformer_encoder.layers.5.linear2.bias\n",
      "loaded: transformer_encoder.layers.5.norm1.weight\n",
      "loaded: transformer_encoder.layers.5.norm1.bias\n",
      "loaded: transformer_encoder.layers.5.norm2.weight\n",
      "loaded: transformer_encoder.layers.5.norm2.bias\n",
      "loaded: token_encoder.weight\n",
      "Loaded pre-trained model with success.\n",
      "Epoch: 1, Batch: 21, Loss: 0.8144706196329566, Val Loss: 0.5564384203065526, SRCC_test = 0.7086434398934398\n",
      "Epoch: 2, Batch: 21, Loss: 0.5361256445391794, Val Loss: 0.5147687819871035, SRCC_test = 0.7795163170163171\n",
      "Epoch: 3, Batch: 21, Loss: 0.49649426073170777, Val Loss: 0.4582538672468879, SRCC_test = 0.7992112054612052\n",
      "Epoch: 4, Batch: 21, Loss: 0.46229023444518613, Val Loss: 0.4545169052752582, SRCC_test = 0.8108427095170835\n",
      "Epoch: 5, Batch: 21, Loss: 0.44289075524619453, Val Loss: 0.4348133314739574, SRCC_test = 0.8194875827200169\n",
      "Epoch: 6, Batch: 21, Loss: 0.4410204709915633, Val Loss: 0.4454718272794377, SRCC_test = 0.8240711402647025\n",
      "Epoch: 7, Batch: 21, Loss: 0.4365318983458401, Val Loss: 0.42413353513587604, SRCC_test = 0.8166431660956914\n",
      "Epoch: 8, Batch: 21, Loss: 0.41994821188155185, Val Loss: 0.43162693218751386, SRCC_test = 0.8386732337179524\n",
      "Epoch: 9, Batch: 21, Loss: 0.41807713434937294, Val Loss: 0.43118337474086066, SRCC_test = 0.8246809478154131\n",
      "Epoch: 10, Batch: 21, Loss: 0.4161204169975238, Val Loss: 0.4019351615147157, SRCC_test = 0.844106920297456\n",
      "Epoch: 11, Batch: 21, Loss: 0.3983466682139407, Val Loss: 0.43359410898251965, SRCC_test = 0.8348591834914838\n",
      "Epoch: 12, Batch: 21, Loss: 0.39916904186934565, Val Loss: 0.44889056140726263, SRCC_test = 0.8268636383009672\n",
      "Epoch: 13, Batch: 21, Loss: 0.3987432862265726, Val Loss: 0.40255324813452636, SRCC_test = 0.8277415472452035\n",
      "Epoch: 14, Batch: 21, Loss: 0.3880962628996774, Val Loss: 0.46250344677404925, SRCC_test = 0.8443864693011439\n",
      "Epoch: 15, Batch: 21, Loss: 0.3868120245719224, Val Loss: 0.3912905766205354, SRCC_test = 0.850494666818603\n",
      "Epoch: 16, Batch: 21, Loss: 0.36861099553911875, Val Loss: 0.38983951915394177, SRCC_test = 0.844289672673094\n",
      "Epoch: 17, Batch: 21, Loss: 0.3768622881910774, Val Loss: 0.3983405747196891, SRCC_test = 0.8397670622540191\n",
      "Epoch: 18, Batch: 21, Loss: 0.3753922511352582, Val Loss: 0.3790877651084553, SRCC_test = 0.8547586720553223\n",
      "Epoch: 19, Batch: 21, Loss: 0.3734258550606417, Val Loss: 0.4277039170265198, SRCC_test = 0.8437354225073768\n",
      "Epoch: 20, Batch: 21, Loss: 0.36204391952311055, Val Loss: 0.40563261238011444, SRCC_test = 0.8384776508499819\n",
      "Training model number: 1\n",
      "loaded: pos_encoder.pe\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.0.linear1.weight\n",
      "loaded: transformer_encoder.layers.0.linear1.bias\n",
      "loaded: transformer_encoder.layers.0.linear2.weight\n",
      "loaded: transformer_encoder.layers.0.linear2.bias\n",
      "loaded: transformer_encoder.layers.0.norm1.weight\n",
      "loaded: transformer_encoder.layers.0.norm1.bias\n",
      "loaded: transformer_encoder.layers.0.norm2.weight\n",
      "loaded: transformer_encoder.layers.0.norm2.bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.1.linear1.weight\n",
      "loaded: transformer_encoder.layers.1.linear1.bias\n",
      "loaded: transformer_encoder.layers.1.linear2.weight\n",
      "loaded: transformer_encoder.layers.1.linear2.bias\n",
      "loaded: transformer_encoder.layers.1.norm1.weight\n",
      "loaded: transformer_encoder.layers.1.norm1.bias\n",
      "loaded: transformer_encoder.layers.1.norm2.weight\n",
      "loaded: transformer_encoder.layers.1.norm2.bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.2.linear1.weight\n",
      "loaded: transformer_encoder.layers.2.linear1.bias\n",
      "loaded: transformer_encoder.layers.2.linear2.weight\n",
      "loaded: transformer_encoder.layers.2.linear2.bias\n",
      "loaded: transformer_encoder.layers.2.norm1.weight\n",
      "loaded: transformer_encoder.layers.2.norm1.bias\n",
      "loaded: transformer_encoder.layers.2.norm2.weight\n",
      "loaded: transformer_encoder.layers.2.norm2.bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.3.linear1.weight\n",
      "loaded: transformer_encoder.layers.3.linear1.bias\n",
      "loaded: transformer_encoder.layers.3.linear2.weight\n",
      "loaded: transformer_encoder.layers.3.linear2.bias\n",
      "loaded: transformer_encoder.layers.3.norm1.weight\n",
      "loaded: transformer_encoder.layers.3.norm1.bias\n",
      "loaded: transformer_encoder.layers.3.norm2.weight\n",
      "loaded: transformer_encoder.layers.3.norm2.bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.4.linear1.weight\n",
      "loaded: transformer_encoder.layers.4.linear1.bias\n",
      "loaded: transformer_encoder.layers.4.linear2.weight\n",
      "loaded: transformer_encoder.layers.4.linear2.bias\n",
      "loaded: transformer_encoder.layers.4.norm1.weight\n",
      "loaded: transformer_encoder.layers.4.norm1.bias\n",
      "loaded: transformer_encoder.layers.4.norm2.weight\n",
      "loaded: transformer_encoder.layers.4.norm2.bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.5.linear1.weight\n",
      "loaded: transformer_encoder.layers.5.linear1.bias\n",
      "loaded: transformer_encoder.layers.5.linear2.weight\n",
      "loaded: transformer_encoder.layers.5.linear2.bias\n",
      "loaded: transformer_encoder.layers.5.norm1.weight\n",
      "loaded: transformer_encoder.layers.5.norm1.bias\n",
      "loaded: transformer_encoder.layers.5.norm2.weight\n",
      "loaded: transformer_encoder.layers.5.norm2.bias\n",
      "loaded: token_encoder.weight\n",
      "Loaded pre-trained model with success.\n",
      "Epoch: 1, Batch: 21, Loss: 0.7619006205140875, Val Loss: 0.5110590092160485, SRCC_test = 0.7521166333666333\n",
      "Epoch: 2, Batch: 21, Loss: 0.523395659548513, Val Loss: 0.4784669578075409, SRCC_test = 0.7768398268398268\n",
      "Epoch: 3, Batch: 21, Loss: 0.492557799213388, Val Loss: 0.46763729778203095, SRCC_test = 0.8013272185928717\n",
      "Epoch: 4, Batch: 21, Loss: 0.4644069353516182, Val Loss: 0.5251812907782468, SRCC_test = 0.7994692807192808\n",
      "Epoch: 5, Batch: 21, Loss: 0.48085805941163823, Val Loss: 0.44946330243890936, SRCC_test = 0.8060229290630633\n",
      "Epoch: 6, Batch: 21, Loss: 0.4383626570192616, Val Loss: 0.48327249559489166, SRCC_test = 0.814928209735008\n",
      "Epoch: 7, Batch: 21, Loss: 0.4266443533843823, Val Loss: 0.4411947727203369, SRCC_test = 0.8099279075158641\n",
      "Epoch: 8, Batch: 21, Loss: 0.4203438494312629, Val Loss: 0.42543415318835864, SRCC_test = 0.8184286622047402\n",
      "Epoch: 9, Batch: 21, Loss: 0.4157247057791506, Val Loss: 0.4200576029040597, SRCC_test = 0.8268356643356642\n",
      "Epoch: 10, Batch: 21, Loss: 0.4103322561537282, Val Loss: 0.4220071177590977, SRCC_test = 0.8235104748093722\n",
      "Epoch: 11, Batch: 21, Loss: 0.4072206224618333, Val Loss: 0.4020457443865863, SRCC_test = 0.8265777870218567\n",
      "Epoch: 12, Batch: 21, Loss: 0.38764779989639025, Val Loss: 0.4093786694786765, SRCC_test = 0.837374564367591\n",
      "Epoch: 13, Batch: 21, Loss: 0.4067381094680743, Val Loss: 0.4702729474414479, SRCC_test = 0.8281822047791431\n",
      "Epoch: 14, Batch: 21, Loss: 0.40934025839473426, Val Loss: 0.4249418188225139, SRCC_test = 0.8289994144555091\n",
      "Epoch: 15, Batch: 21, Loss: 0.38568123873699917, Val Loss: 0.43448820032856683, SRCC_test = 0.8361859111161176\n",
      "Epoch: 16, Batch: 21, Loss: 0.38795844021807896, Val Loss: 0.39590243995189667, SRCC_test = 0.8396819245717296\n",
      "Epoch: 17, Batch: 21, Loss: 0.3909968924656343, Val Loss: 0.40216253156011755, SRCC_test = 0.8316080249544389\n",
      "Epoch: 18, Batch: 21, Loss: 0.36861041891440915, Val Loss: 0.406350087035786, SRCC_test = 0.839953125113002\n",
      "Epoch: 19, Batch: 21, Loss: 0.3718546170197176, Val Loss: 0.3829200023954565, SRCC_test = 0.8370437412999763\n",
      "Epoch: 20, Batch: 21, Loss: 0.36833500326349494, Val Loss: 0.3898544812744314, SRCC_test = 0.8396880601578609\n",
      "Training model number: 2\n",
      "loaded: pos_encoder.pe\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.0.linear1.weight\n",
      "loaded: transformer_encoder.layers.0.linear1.bias\n",
      "loaded: transformer_encoder.layers.0.linear2.weight\n",
      "loaded: transformer_encoder.layers.0.linear2.bias\n",
      "loaded: transformer_encoder.layers.0.norm1.weight\n",
      "loaded: transformer_encoder.layers.0.norm1.bias\n",
      "loaded: transformer_encoder.layers.0.norm2.weight\n",
      "loaded: transformer_encoder.layers.0.norm2.bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.1.linear1.weight\n",
      "loaded: transformer_encoder.layers.1.linear1.bias\n",
      "loaded: transformer_encoder.layers.1.linear2.weight\n",
      "loaded: transformer_encoder.layers.1.linear2.bias\n",
      "loaded: transformer_encoder.layers.1.norm1.weight\n",
      "loaded: transformer_encoder.layers.1.norm1.bias\n",
      "loaded: transformer_encoder.layers.1.norm2.weight\n",
      "loaded: transformer_encoder.layers.1.norm2.bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.2.linear1.weight\n",
      "loaded: transformer_encoder.layers.2.linear1.bias\n",
      "loaded: transformer_encoder.layers.2.linear2.weight\n",
      "loaded: transformer_encoder.layers.2.linear2.bias\n",
      "loaded: transformer_encoder.layers.2.norm1.weight\n",
      "loaded: transformer_encoder.layers.2.norm1.bias\n",
      "loaded: transformer_encoder.layers.2.norm2.weight\n",
      "loaded: transformer_encoder.layers.2.norm2.bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.3.linear1.weight\n",
      "loaded: transformer_encoder.layers.3.linear1.bias\n",
      "loaded: transformer_encoder.layers.3.linear2.weight\n",
      "loaded: transformer_encoder.layers.3.linear2.bias\n",
      "loaded: transformer_encoder.layers.3.norm1.weight\n",
      "loaded: transformer_encoder.layers.3.norm1.bias\n",
      "loaded: transformer_encoder.layers.3.norm2.weight\n",
      "loaded: transformer_encoder.layers.3.norm2.bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.4.linear1.weight\n",
      "loaded: transformer_encoder.layers.4.linear1.bias\n",
      "loaded: transformer_encoder.layers.4.linear2.weight\n",
      "loaded: transformer_encoder.layers.4.linear2.bias\n",
      "loaded: transformer_encoder.layers.4.norm1.weight\n",
      "loaded: transformer_encoder.layers.4.norm1.bias\n",
      "loaded: transformer_encoder.layers.4.norm2.weight\n",
      "loaded: transformer_encoder.layers.4.norm2.bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.5.linear1.weight\n",
      "loaded: transformer_encoder.layers.5.linear1.bias\n",
      "loaded: transformer_encoder.layers.5.linear2.weight\n",
      "loaded: transformer_encoder.layers.5.linear2.bias\n",
      "loaded: transformer_encoder.layers.5.norm1.weight\n",
      "loaded: transformer_encoder.layers.5.norm1.bias\n",
      "loaded: transformer_encoder.layers.5.norm2.weight\n",
      "loaded: transformer_encoder.layers.5.norm2.bias\n",
      "loaded: token_encoder.weight\n",
      "Loaded pre-trained model with success.\n",
      "Epoch: 1, Batch: 21, Loss: 0.8371964435229141, Val Loss: 0.5854313346472654, SRCC_test = 0.6667846865438363\n",
      "Epoch: 2, Batch: 21, Loss: 0.5504264161827859, Val Loss: 0.4916932935064489, SRCC_test = 0.7622419247419248\n",
      "Epoch: 3, Batch: 21, Loss: 0.5015953300374277, Val Loss: 0.48761045932769775, SRCC_test = 0.7785416762630807\n",
      "Epoch: 4, Batch: 21, Loss: 0.46238908138167994, Val Loss: 0.46293459697203204, SRCC_test = 0.7940896474817042\n",
      "Epoch: 5, Batch: 21, Loss: 0.4656803681609336, Val Loss: 0.4538025287064639, SRCC_test = 0.7899725274725273\n",
      "Epoch: 6, Batch: 21, Loss: 0.44540380661407214, Val Loss: 0.46961055018685083, SRCC_test = 0.81247045669601\n",
      "Epoch: 7, Batch: 21, Loss: 0.4363309560197123, Val Loss: 0.45008747008713806, SRCC_test = 0.8096797271124718\n",
      "Epoch: 8, Batch: 21, Loss: 0.4308300179042173, Val Loss: 0.43298613212325354, SRCC_test = 0.8125582750582748\n",
      "Epoch: 9, Batch: 21, Loss: 0.4345493085598678, Val Loss: 0.42700710757212207, SRCC_test = 0.822588759525237\n",
      "Epoch: 10, Batch: 21, Loss: 0.4486214779735951, Val Loss: 0.4332799979231574, SRCC_test = 0.8171925590380684\n",
      "Epoch: 11, Batch: 21, Loss: 0.40559310290250883, Val Loss: 0.48591676489873364, SRCC_test = 0.8350584534480824\n",
      "Epoch: 12, Batch: 21, Loss: 0.4035657195562727, Val Loss: 0.4253947531635111, SRCC_test = 0.8336050069273191\n",
      "Epoch: 13, Batch: 21, Loss: 0.3864952908473068, Val Loss: 0.45946571637283673, SRCC_test = 0.8108075797261493\n",
      "Epoch: 14, Batch: 21, Loss: 0.3893097357803516, Val Loss: 0.41586119072003797, SRCC_test = 0.8199306393237703\n",
      "Epoch: 15, Batch: 21, Loss: 0.38518475916948214, Val Loss: 0.40051801096309314, SRCC_test = 0.8367670736798839\n",
      "Epoch: 16, Batch: 21, Loss: 0.380363185084268, Val Loss: 0.4061862812800841, SRCC_test = 0.8403280888215602\n",
      "Epoch: 17, Batch: 21, Loss: 0.3840342194176792, Val Loss: 0.40637457370758057, SRCC_test = 0.8344762688443498\n",
      "Epoch: 18, Batch: 21, Loss: 0.3728010795089636, Val Loss: 0.45782946185632184, SRCC_test = 0.824793008792486\n",
      "Epoch: 19, Batch: 21, Loss: 0.37784824712892595, Val Loss: 0.4501873566345735, SRCC_test = 0.8374535404976865\n",
      "Epoch: 20, Batch: 21, Loss: 0.3719580073035165, Val Loss: 0.42649139870296826, SRCC_test = 0.8354446075139369\n",
      "Training model number: 3\n",
      "loaded: pos_encoder.pe\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.0.linear1.weight\n",
      "loaded: transformer_encoder.layers.0.linear1.bias\n",
      "loaded: transformer_encoder.layers.0.linear2.weight\n",
      "loaded: transformer_encoder.layers.0.linear2.bias\n",
      "loaded: transformer_encoder.layers.0.norm1.weight\n",
      "loaded: transformer_encoder.layers.0.norm1.bias\n",
      "loaded: transformer_encoder.layers.0.norm2.weight\n",
      "loaded: transformer_encoder.layers.0.norm2.bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.1.linear1.weight\n",
      "loaded: transformer_encoder.layers.1.linear1.bias\n",
      "loaded: transformer_encoder.layers.1.linear2.weight\n",
      "loaded: transformer_encoder.layers.1.linear2.bias\n",
      "loaded: transformer_encoder.layers.1.norm1.weight\n",
      "loaded: transformer_encoder.layers.1.norm1.bias\n",
      "loaded: transformer_encoder.layers.1.norm2.weight\n",
      "loaded: transformer_encoder.layers.1.norm2.bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.2.linear1.weight\n",
      "loaded: transformer_encoder.layers.2.linear1.bias\n",
      "loaded: transformer_encoder.layers.2.linear2.weight\n",
      "loaded: transformer_encoder.layers.2.linear2.bias\n",
      "loaded: transformer_encoder.layers.2.norm1.weight\n",
      "loaded: transformer_encoder.layers.2.norm1.bias\n",
      "loaded: transformer_encoder.layers.2.norm2.weight\n",
      "loaded: transformer_encoder.layers.2.norm2.bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.3.linear1.weight\n",
      "loaded: transformer_encoder.layers.3.linear1.bias\n",
      "loaded: transformer_encoder.layers.3.linear2.weight\n",
      "loaded: transformer_encoder.layers.3.linear2.bias\n",
      "loaded: transformer_encoder.layers.3.norm1.weight\n",
      "loaded: transformer_encoder.layers.3.norm1.bias\n",
      "loaded: transformer_encoder.layers.3.norm2.weight\n",
      "loaded: transformer_encoder.layers.3.norm2.bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.4.linear1.weight\n",
      "loaded: transformer_encoder.layers.4.linear1.bias\n",
      "loaded: transformer_encoder.layers.4.linear2.weight\n",
      "loaded: transformer_encoder.layers.4.linear2.bias\n",
      "loaded: transformer_encoder.layers.4.norm1.weight\n",
      "loaded: transformer_encoder.layers.4.norm1.bias\n",
      "loaded: transformer_encoder.layers.4.norm2.weight\n",
      "loaded: transformer_encoder.layers.4.norm2.bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "loaded: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "loaded: transformer_encoder.layers.5.linear1.weight\n",
      "loaded: transformer_encoder.layers.5.linear1.bias\n",
      "loaded: transformer_encoder.layers.5.linear2.weight\n",
      "loaded: transformer_encoder.layers.5.linear2.bias\n",
      "loaded: transformer_encoder.layers.5.norm1.weight\n",
      "loaded: transformer_encoder.layers.5.norm1.bias\n",
      "loaded: transformer_encoder.layers.5.norm2.weight\n",
      "loaded: transformer_encoder.layers.5.norm2.bias\n",
      "loaded: token_encoder.weight\n",
      "Loaded pre-trained model with success.\n",
      "Epoch: 1, Batch: 21, Loss: 0.7932094790962305, Val Loss: 0.6299725229089911, SRCC_test = 0.6930486180486178\n",
      "Epoch: 2, Batch: 21, Loss: 0.5366800270053778, Val Loss: 0.5022873729467392, SRCC_test = 0.7653000865220125\n",
      "Epoch: 3, Batch: 21, Loss: 0.48087637779418, Val Loss: 0.5168781768191945, SRCC_test = 0.7597120849318153\n",
      "Epoch: 4, Batch: 21, Loss: 0.4667322320884533, Val Loss: 0.48004144159230316, SRCC_test = 0.782484592738031\n",
      "Epoch: 5, Batch: 21, Loss: 0.44611989279811304, Val Loss: 0.49378450350327924, SRCC_test = 0.7992022517602991\n",
      "Epoch: 6, Batch: 21, Loss: 0.44070310739988694, Val Loss: 0.4570957964116877, SRCC_test = 0.7812699128569937\n",
      "Epoch: 7, Batch: 21, Loss: 0.42111654060610226, Val Loss: 0.44418887523087586, SRCC_test = 0.7954570395096717\n",
      "Epoch: 8, Batch: 21, Loss: 0.4273582117611103, Val Loss: 0.4673289426348426, SRCC_test = 0.7999192510953315\n",
      "Epoch: 9, Batch: 21, Loss: 0.4171140582373973, Val Loss: 0.43624527616934344, SRCC_test = 0.8005742290778411\n",
      "Epoch: 10, Batch: 21, Loss: 0.41701751076773313, Val Loss: 0.4593704573132775, SRCC_test = 0.8107916705850435\n",
      "Epoch: 11, Batch: 21, Loss: 0.4087257529242655, Val Loss: 0.4312697703188116, SRCC_test = 0.8042025662346671\n",
      "Epoch: 12, Batch: 21, Loss: 0.40027534760785904, Val Loss: 0.41582701152021234, SRCC_test = 0.8186833999333998\n",
      "Epoch: 13, Batch: 21, Loss: 0.3965909621688757, Val Loss: 0.5365396683866327, SRCC_test = 0.8158036680834383\n",
      "Epoch: 14, Batch: 21, Loss: 0.4042115378915594, Val Loss: 0.42897307737307117, SRCC_test = 0.8201260557750121\n",
      "Epoch: 15, Batch: 21, Loss: 0.38233367010448754, Val Loss: 0.42780056460337207, SRCC_test = 0.8077884062605588\n",
      "Epoch: 16, Batch: 21, Loss: 0.39214500851845474, Val Loss: 0.5726333314722235, SRCC_test = 0.8206970438502386\n",
      "Epoch: 17, Batch: 21, Loss: 0.3960800090532624, Val Loss: 0.4317195415496826, SRCC_test = 0.8247783020069562\n",
      "Epoch: 18, Batch: 21, Loss: 0.3743505163139172, Val Loss: 0.4056660776788538, SRCC_test = 0.8320642898128945\n",
      "Epoch: 19, Batch: 21, Loss: 0.3820985873763481, Val Loss: 0.45414695008234546, SRCC_test = 0.8333235452621984\n",
      "Epoch: 20, Batch: 21, Loss: 0.3726329743192437, Val Loss: 0.4231554242697629, SRCC_test = 0.8333431235809265\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "best_valid_mae = np.inf\n",
    "best_valid_roc_auc = 0\n",
    "best_srcc_valid = 0\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "num_epoch = 20\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Training model number: {i}\")\n",
    "    loss_history, val_history, srcc_val_history = [], [], []\n",
    "\n",
    "    transformer_SMILES = Transformer(**config['Transformer'])\n",
    "    model_pre = _load_pre_trained_weights(model = transformer_SMILES, mode = 'cgcnn')\n",
    "    model = RegressionTransformer(model = model_pre)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    optimizer = optim.Adam(model.regression_head.parameters(), lr = 0.01)\n",
    "    optimizer_t = optim.Adam(model.model.parameters(), lr = 0.00005)\n",
    "\n",
    "    model.train()\n",
    "    #train fold\n",
    "    some_fold_train = MOF_ID_Dataset(data = folds[i][0], tokenizer = tokenizer)\n",
    "\n",
    "    n_fold_train = DataLoader(\n",
    "                        some_fold_train, batch_size=batch_size, drop_last=True, shuffle=True\n",
    "                    )\n",
    "    \n",
    "    #test fold\n",
    "    some_test_fold = MOF_ID_Dataset(data = folds[i][1], tokenizer = tokenizer)\n",
    "\n",
    "    n_fold_test = DataLoader(\n",
    "                        some_test_fold, batch_size=batch_size, drop_last=True, shuffle=True\n",
    "                    )\n",
    "    \n",
    "    for epoch_counter in range(num_epoch):\n",
    "        loss_temp = []\n",
    "        for bn, (input1, target) in enumerate(n_fold_train):\n",
    "            if config['cuda']:\n",
    "                input_var_1 = input1.to(device)\n",
    "                #input_var_2 = input2.to(device)\n",
    "            else:\n",
    "                input_var_1 = input1.to(device)\n",
    "                #input_var_2 = input2.to(device)\n",
    "            \n",
    "            if config['cuda']:\n",
    "                #target_var = Variable(target_normed.to(device, non_blocking=True)) #experimenting with normalization vs non-norm\n",
    "                target_var = Variable(target.to(device, non_blocking=True))\n",
    "            else:\n",
    "                #target_var = Variable(target_normed)\n",
    "                target_var = Variable(target)\n",
    "            \n",
    "            if config['cuda']:\n",
    "                model = model.to(device)\n",
    "\n",
    "            target_var = target_var.reshape(-1, 1)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var_1)\n",
    "            output = output.reshape(-1, 1)\n",
    "\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_t.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer_t.step()\n",
    "            n_iter += 1\n",
    "\n",
    "            loss_temp.append(loss.item())\n",
    "        \n",
    "        loss_history.append(np.mean(loss_temp))\n",
    "\n",
    "        val_temp = []\n",
    "        srcc_val_temp = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for bn, (input1, target) in enumerate(n_fold_test):\n",
    "                if config['cuda']:\n",
    "                    input_var_1 = input1.to(device)\n",
    "                    #input_var_2 = input2.to(device)\n",
    "                else:\n",
    "                    input_var_1 = input1.to(device)\n",
    "                    #input_var_2 = input2.to(device)\n",
    "                \n",
    "                \n",
    "                if config['cuda']:\n",
    "                    #target_var = Variable(target_normed.to(device, non_blocking=True))\n",
    "                    target_var = Variable(target.to(device, non_blocking=True))\n",
    "                else:\n",
    "                    #target_var = Variable(target_normed)\n",
    "                    target_var = Variable(target)\n",
    "\n",
    "                target_var = target_var.reshape(-1, 1)\n",
    "                # compute output\n",
    "                output = model(input_var_1)\n",
    "                output = output.reshape(-1, 1)\n",
    "\n",
    "                loss_val = criterion(output, target_var)\n",
    "                val_temp.append(loss_val.item())\n",
    "                srcc_val_temp.append(scipy.stats.spearmanr(output.cpu().numpy(), target_var.cpu().numpy())[0])\n",
    "        \n",
    "        srcc_val_history.append(np.mean(srcc_val_temp))\n",
    "\n",
    "        \n",
    "        val_history.append(np.mean(val_temp))\n",
    "\n",
    "        if epoch_counter % config['log_every_n_steps'] == 0:\n",
    "            print(f'Epoch: {epoch_counter+1}, Batch: {bn}, Loss: {loss_history[-1]}, Val Loss: {val_history[-1]}, SRCC_test = {srcc_val_history[-1]}')\n",
    "        \n",
    "    torch.save(model.state_dict(), f'model_ft_bandgap_{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMILES_to_property(smiles, model, tokenizer, device):\n",
    "    token = np.array([tokenizer.encode(smiles, max_length=512, truncation=True,padding='max_length')])\n",
    "    token = torch.from_numpy(np.asarray(token))\n",
    "\n",
    "    token = token.to(device)\n",
    "    return model(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3134]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMILES_to_property('[Zn]12.OC(=O)C1=CC=C(C=C1)C(O2)=O', model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Learning curve')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.plot(val_history)\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Learning curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
